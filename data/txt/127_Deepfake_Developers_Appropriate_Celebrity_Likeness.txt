A viral deepfake video showed media superstars who appeared to support a cause -- but it was made without their participation or permission.

What's new:  The  video  shows AI-generated likenesses of 20 Jewish celebrities ranging from Scarlett Johansson to Simon & Garfunkel. They appear wearing T-shirts that feature a middle finger inscribed with the Star of David above the word "KANYE." The clip, which ends with the words "Enough is enough" followed by "Join the fight against antisemitism," responds to rapper Kanye West, who sold T-shirts emblazoned with swastikas on Shopify before the ecommerce platform shut down his store.

Who created it:  Israeli developers Guy Bar and Ori Bejerano generated the video to spark a conversation about antisemitism, Bar  told   The Jerusalem Post . The team didn't reveal the AI models, editing tools, or techniques used to produce the video.

Johansson reacts:  Scarlett Johansson  denounced  the clip and urged the U.S. to regulate deepfakes. In 2024, she  objected  to one of the voices of OpenAI's voice assistant, which she claimed resembled her own voice, leading the company to remove that voice from its service. The prior year, her attorneys ordered a company to stop using an unauthorized AI-generated version of her image in an advertisement.

Likenesses up for grabs:  Existing U.S. laws protect some uses of a celebrity's likeness in the form of a photo, drawing, or human lookalike, but they don't explicitly protect against reproduction by AI systems. This leaves celebrities and public figures with limited recourse against unauthorized deepfakes.

U.S. lawmakers have  introduced  legislation that targets deepfake pornography, but it covers only sexually explicit deepfakes. The  right of publicity , which falls under trademark law, offers some protection against the unauthorized use of a person's identity. However, it varies by state and provides broad exceptions for news, satire, and fine art. While some states outlaw misappropriation of names or likenesses, existing laws primarily target traditional forms of image misuse, such as false endorsements or unauthorized commercial exploitation. They do not explicitly cover AI-generated deepfakes used for noncommercial, political, or satirical purposes. A 2023  agreement  between Hollywood actors and movie studios protects actors against such uses of AI-generated images of their likenesses in films. However, it doesn't apply to deepfakes that are produced independently for distribution via social media networks.

Why it matters:  Non-consensual deepfake pornography is widely condemned, but AI enables many other non-consensual uses of someone's likeness, and their limits are not yet consistently coded into law. If the creators of the video that appropriated the images of celebrities had responded to Johansson's criticism with an AI-generated satire, would that be a legitimate exercise of free speech or another misuse of AI? Previously, an ambiguous legal framework may have been acceptable because such images, and thus lawsuits arising from them, were uncommon. Now, as synthetic likenesses of specific people become easier to generate, clear legal boundaries are needed to keep misuses in check.

We're thinking:  Creating unauthorized lookalikes of existing people is not a good way to advance any cause, however worthy. Developers should work with businesses policymakers to establish standards that differentiate legitimate uses from unfair or misleading exploitation.